{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8bd554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c357d8e",
   "metadata": {},
   "source": [
    "# Comparing Testing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913c57c8",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865f3d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'./testingProcessed' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    model = scaler.fit(df)\n",
    "    x_train = model.transform(df)\n",
    "    fileNameActual=filename.replace(\"./testingProcessed/\",\"\")\n",
    "    mj = joblib.load('model_joblib_logistic_regression')\n",
    "    y_pred = mj.predict(x_train)\n",
    "    elements_count = collections.Counter(y_pred)\n",
    "    # printing the element and the frequency\n",
    "    print(fileNameActual+\":\")\n",
    "    print(elements_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bd8a25",
   "metadata": {},
   "source": [
    "### K- Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'./testingProcessed' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    model = scaler.fit(df)\n",
    "    x_train = model.transform(df)\n",
    "    fileNameActual=filename.replace(\"./testingProcessed/\",\"\")\n",
    "    mj = joblib.load('model_joblib_knn')\n",
    "    y_pred = mj.predict(x_train)\n",
    "    elements_count = collections.Counter(y_pred)\n",
    "    # printing the element and the frequency\n",
    "    print(fileNameActual+\":\")\n",
    "    print(elements_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89314273",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0694e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'./testingProcessed' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    x_train=df\n",
    "    fileNameActual=filename.replace(\"./testingProcessed/\",\"\")\n",
    "    mj = joblib.load('model_joblib_decision_tree')\n",
    "    y_pred = mj.predict(x_train)\n",
    "    elements_count = collections.Counter(y_pred)\n",
    "    # printing the element and the frequency\n",
    "    print(fileNameActual+\":\")\n",
    "    print(elements_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c201d7ad",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d25706",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'./testingProcessed' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    x_train=df\n",
    "    fileNameActual=filename.replace(\"./testingProcessed/\",\"\")\n",
    "    mj = joblib.load('model_joblib_random_forest')\n",
    "    y_pred = mj.predict(x_train)\n",
    "    elements_count = collections.Counter(y_pred)\n",
    "    # printing the element and the frequency\n",
    "    print(fileNameActual+\":\")\n",
    "    print(elements_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d724e841",
   "metadata": {},
   "source": [
    "### Support Vector Machines - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'./testingProcessed' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    x_train=df\n",
    "    fileNameActual=filename.replace(\"./testingProcessed/\",\"\")\n",
    "    mj = joblib.load('model_joblib_svm_linear')\n",
    "    y_pred = mj.predict(x_train)\n",
    "    elements_count = collections.Counter(y_pred)\n",
    "    # printing the element and the frequency\n",
    "    print(fileNameActual+\":\")\n",
    "    print(elements_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51be57a7",
   "metadata": {},
   "source": [
    "### Support Vector Machines - Radial Basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4607d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'./testingProcessed' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    x_train=df\n",
    "    fileNameActual=filename.replace(\"./testingProcessed/\",\"\")\n",
    "    mj = joblib.load('model_joblib_svm_rbf')\n",
    "    y_pred = mj.predict(x_train)\n",
    "    elements_count = collections.Counter(y_pred)\n",
    "    # printing the element and the frequency\n",
    "    print(fileNameActual+\":\")\n",
    "    print(elements_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f898d29c",
   "metadata": {},
   "source": [
    "### Support Vector Machines - Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b31da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'./testingProcessed' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    x_train=df\n",
    "    fileNameActual=filename.replace(\"./testingProcessed/\",\"\")\n",
    "    mj = joblib.load('model_joblib_svm_poly')\n",
    "    y_pred = mj.predict(x_train)\n",
    "    elements_count = collections.Counter(y_pred)\n",
    "    # printing the element and the frequency\n",
    "    print(fileNameActual+\":\")\n",
    "    print(elements_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1d1f30",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'./testingProcessed' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    x_train=df\n",
    "    fileNameActual=filename.replace(\"./testingProcessed/\",\"\")\n",
    "    mj = joblib.load('model_joblib_gaussian_naive_bayes')\n",
    "    y_pred = mj.predict(x_train)\n",
    "    elements_count = collections.Counter(y_pred)\n",
    "    # printing the element and the frequency\n",
    "    print(fileNameActual+\":\")\n",
    "    print(elements_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
